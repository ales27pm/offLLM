      import torch
      from transformers import LlamaForCausalLM, AutoConfig
      import coremltools as ct
      import numpy as np

      model_id = "cognitivecomputations/Dolphin3.0-Llama3.2-3B"
      config = AutoConfig.from_pretrained(model_id)
      torch_model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).eval()

      class BaselineLlamaForCausalLM(torch.nn.Module):
          def __init__(self, model):
              super().__init__()
              self.model = model

          @torch.no_grad()
          def forward(self, input_ids: torch.LongTensor, attention_mask: torch.LongTensor) -> torch.Tensor:
              out = self.model(input_ids=input_ids, attention_mask=attention_mask, use_cache=False)
              return out.logits

      wrapper = BaselineLlamaForCausalLM(torch_model)

      batch_size, context_size = 1, 2048
      input_shape = (batch_size, context_size)
      example_input_ids = torch.zeros(input_shape, dtype=torch.int64)
      example_attention_mask = torch.zeros(input_shape, dtype=torch.int64)

      traced_model = torch.jit.trace(wrapper, (example_input_ids, example_attention_mask))

      inputs = [
          ct.TensorType(name="input_ids", shape=input_shape, dtype=np.int32),
          ct.TensorType(name="attention_mask", shape=input_shape, dtype=np.int32),
      ]
      outputs = [ct.TensorType(name="logits", dtype=np.float16)]

      mlmodel = ct.convert(
          traced_model,
          inputs=inputs,
          outputs=outputs,
          minimum_deployment_target=ct.target.macOS13,
          skip_model_load=True,
      )

      # Quantization
      quant_config = ct.optimize.coreml.OpLinearQuantizerConfig(
          mode="linear_symmetric",
          dtype=ct.optimize.coreml.data_types.int4,
          granularity="per_block",
          block_size=32,
      )
      quantized_mlmodel = ct.optimize.coreml.linear_quantize_weights(mlmodel, config=quant_config)

      quantized_mlmodel.save("Dolphin3.0-Llama3.2-3B.mlmodel")
      EOF
  - name: Commit the converted model
    run: |
      git config user.name github-actions
      git config user.email github-actions@github.com
      git add Dolphin3.0-Llama3.2-3B.mlmodel
      git commit -m "Add converted Core ML model" || echo "No changes to commit"
      git push
  - name: Upload artifact
    uses: actions/upload-artifact@v4
    with:
      name: coreml-model
      path: Dolphin3.0-Llama3.2-3B.mlmodel
